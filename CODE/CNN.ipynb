{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e38069d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image # For handling the images\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Import different Keras functionalities\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Input, Flatten, Dropout, concatenate, BatchNormalization\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902a9e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_subjects = \"../DATA/dogs-vs-cats/train\"\n",
    "for f_name in os.listdir(path_subjects):\n",
    "    img = Image.open(path_subjects + '/' + f_name)\n",
    "    plt.imshow(img, cmap='rgb', vmin=0, vmax=255)\n",
    "    plt.title('subject: ' + str(f_name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d907ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_rootdir = \"./CNN-results/\"\n",
    "weights_path = './CNN-results/weights.h5'\n",
    "loss_img_name = './CNN-results/loss.png'\n",
    "accuracy_img_name = './CNN-results/accuracy.png'\n",
    "\n",
    "weights_file = Path(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f560e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize the initial network weights\n",
    "random_seed = True\n",
    "\n",
    "# Parameters that characterizes the images, size and image type\n",
    "img_width=128\n",
    "img_height=128\n",
    "img_channels=3\n",
    "img_mode='rgb'\n",
    "\n",
    "# Parameters that configures the training process\n",
    "batch_size=32\n",
    "epochs = 20\n",
    "lrate = 0.001\n",
    "min_lrate = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25ad84b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=os.listdir(\"../DATA/dogs-vs-cats/train\")\n",
    "categories=[]\n",
    "for f_name in filenames:\n",
    "    category=f_name.split('.')[0]\n",
    "    if category=='dog':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "df=pd.DataFrame({\n",
    "    'filename':filenames,\n",
    "    'category':categories\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5388f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSimpleNetwork(img_width,img_height,img_channels):\n",
    "    model=Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32,(3,3),activation='relu',input_shape=(img_width,img_height,img_channels)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7b32d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNetworkVGG16(img_width,img_height,img_channels):\n",
    "    #  dropout rate for FC layers\n",
    "    dropout=0.5\n",
    "\n",
    "    # CNN architecture\n",
    "\n",
    "    input_image = Input(shape=(32,32,3))\n",
    "    x1 = Conv2D(64, (3, 3),padding='same', activation='relu')(input_image)\n",
    "    x1 = Conv2D(64, (3, 3),padding='same', activation='relu')(x1)\n",
    "    x1 = MaxPooling2D((2, 2))(x1)\n",
    "\n",
    "    x1 = Conv2D(128, (3, 3),padding='same', activation='relu')(x1)\n",
    "    x1 = Conv2D(128, (3, 3),padding='same', activation='relu')(x1)\n",
    "    x1 = MaxPooling2D((2, 2))(x1)\n",
    "\n",
    "    x1 = Conv2D(256, (3, 3),padding='same', activation='relu')(x1)\n",
    "    x1 = Conv2D(256, (3, 3),padding='same', activation='relu')(x1)\n",
    "    x1 = Conv2D(256, (3, 3),padding='same', activation='relu')(x1)\n",
    "    x1 = MaxPooling2D((2, 2))(x1)\n",
    "\n",
    "    x1 = Conv2D(512, (3, 3),padding='same', activation='relu')(x1)\n",
    "    x1 = Conv2D(512, (3, 3),padding='same', activation='relu')(x1)\n",
    "    x1 = Conv2D(512, (3, 3),padding='same', activation='relu')(x1)\n",
    "    x1 = MaxPooling2D((2, 2))(x1)\n",
    "\n",
    "    x1 = Conv2D(512, (3, 3),padding='same', activation='relu')(x1)\n",
    "    x1 = Conv2D(512, (3, 3),padding='same', activation='relu')(x1)\n",
    "    x1 = Conv2D(512, (3, 3),padding='same', activation='relu')(x1)\n",
    "    x1 = MaxPooling2D((2, 2))(x1)\n",
    "\n",
    "    x1 = Flatten()(x1)\n",
    "\n",
    "    x=Dense(1024, activation='relu', kernel_constraint=maxnorm(3))(x1)\n",
    "    x=Dropout(dropout)(x)\n",
    "\n",
    "    out= Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs = input_image, outputs = out);\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8998473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNetworkResnet(img_width,img_height,img_channels):\n",
    "    #  dropout rate for FC layers\n",
    "    dropout=0.5\n",
    "\n",
    "    # CNN architecture\n",
    "\n",
    "    input_image = Input(shape=(32,32,3))\n",
    "    x1 = Conv2D(64, (3, 3),padding='same', activation='relu')(input_image)\n",
    "    x1 = Conv2D(64, (3, 3),padding='same', activation='relu')(x1)\n",
    "    x1 = MaxPooling2D((2, 2))(x1)\n",
    "\n",
    "    x2 = Conv2D(128, (3, 3),padding='same', activation='relu')(x1)\n",
    "    x3 = Conv2D(128, (3, 3),padding='same')(x2)\n",
    "\n",
    "    x4 = Add()([x3,x2])\n",
    "    x1 = Activation('relu')(x4)\n",
    "\n",
    "    x1 = MaxPooling2D((2, 2))(x1)\n",
    "    x2 = Conv2D(256, (3, 3),padding='same', activation='relu')(x1)\n",
    "    x3 = Conv2D(256, (3, 3),padding='same', activation='relu')(x2)\n",
    "    x3 = Conv2D(256, (3, 3),padding='same')(x3)\n",
    "\n",
    "    x4 = Add()([x3,x2])\n",
    "    x1 = Activation('relu')(x4)\n",
    "\n",
    "    x1 = MaxPooling2D((2, 2))(x1)\n",
    "    x2 = Conv2D(512, (3, 3),padding='same', activation='relu')(x1)\n",
    "    x3 = Conv2D(512, (3, 3),padding='same', activation='relu')(x2)\n",
    "    x3 = Conv2D(512, (3, 3),padding='same')(x3)\n",
    "\n",
    "    x4 = Add()([x3,x2])\n",
    "    x1 = Activation('relu')(x4)\n",
    "\n",
    "    x1 = MaxPooling2D((2, 2))(x1)\n",
    "    x2 = Conv2D(512, (3, 3),padding='same', activation='relu')(x1)\n",
    "    x3 = Conv2D(512, (3, 3),padding='same', activation='relu')(x2)\n",
    "    x3 = Conv2D(512, (3, 3),padding='same')(x3)\n",
    "\n",
    "    x4 = Add()([x3,x2])\n",
    "    x1 = Activation('relu')(x4)\n",
    "\n",
    "    x1 = MaxPooling2D((2, 2))(x1)\n",
    "\n",
    "    x1 = Flatten()(x1)\n",
    "    x=Dense(1024, activation='relu', kernel_constraint=maxnorm(3))(x1)\n",
    "    x=Dropout(dropout)(x)\n",
    "\n",
    "    out= Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs = input_image, outputs = out);\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf340749",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace({0:'cat',1:'dog'})\n",
    "train_df ,validate_df = train_test_split(df,test_size=0.20,random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "total_train=train_df.shape[0]\n",
    "total_validate=validate_df.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b5b595b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 20000 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "if random_seed:\n",
    "    seed = np.random.randint(0,2*31-1)\n",
    "else:\n",
    "    seed = 5\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "#Using ImageGenerator\n",
    "train_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1\n",
    "                                )\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                    \"../DATA/dogs-vs-cats/train/\",\n",
    "                                                    x_col='filename',\n",
    "                                                    y_col='category',\n",
    "                                                    target_size=(img_width,img_height),\n",
    "                                                    class_mode='categorical',\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    color_mode=img_mode,\n",
    "                                                   )\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    \"../DATA/dogs-vs-cats/train/\", \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=(img_width,img_height),\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    color_mode=img_mode,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1\n",
    "                                )\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(train_df,\n",
    "                                                 \"../DATA/dogs-vs-cats/test/\",\n",
    "                                                  x_col='filename',\n",
    "                                                  y_col='category',\n",
    "                                                  target_size=(img_width,img_height),\n",
    "                                                  class_mode='categorical',\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  color_mode=img_mode,\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95467dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model):\n",
    "    \n",
    "    #probar otro compiler con otro optimizer en funci√≥n del modelo que entrenemos\n",
    "    #sdg = SGD(lr=lrate, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "    #adam = Adam(learning_rate=lrate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    rmsprop = RMSprop(learning_rate=lrate, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer= rmsprop ,metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "    \n",
    "    # Define training and validation steps taking into account the number of samples for each process and the batch size    \n",
    "    STEPS_PER_EPOCH_TRAINING =  total_train// batch_size\n",
    "    STEPS_PER_EPOCH_VALIDATION =  total_validate// batch_size\n",
    "    \n",
    "    # Fit the model by using the fit generator\n",
    "    earlystop = EarlyStopping(patience = 10)\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc',patience = 2,verbose = 1,factor = 0.5, min_lr = min_lrate)\n",
    "    history = model.fit_generator(\n",
    "        train_generator, \n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=STEPS_PER_EPOCH_VALIDATION,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH_TRAINING,\n",
    "        callbacks=[earlystop,learning_rate_reduction]\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef151ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleModel = createSimpleNetwork(img_width,img_height,img_channels)\n",
    "#vggModel = createNetworkVGG16(img_width,img_height,img_channels)\n",
    "#resnetModel = createNetworkResnet(img_width,img_height,img_channels)\n",
    "history = trainModel(simpleModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e9bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_save_path = os.path.join(experiment_rootdir, weights_path)\n",
    "simpleModel.save_weights(weights_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9c8305d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './dogs-vs-cats/test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tw/_h7yq1ks6m93h0ly9bzf7d9h0000gn/T/ipykernel_11412/1577002310.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./dogs-vs-cats/test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m test_df = pd.DataFrame({\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m'filename'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m })\n\u001b[1;32m      5\u001b[0m \u001b[0mnb_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dogs-vs-cats/test'"
     ]
    }
   ],
   "source": [
    "test_filenames = os.listdir(\"../DATA/dogs-vs-cats/test\")\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_filenames\n",
    "})\n",
    "nb_samples = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4899d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model by using the getModel function\n",
    "simpleModel = createSimpleNetwork(img_width,img_height,img_channels)\n",
    "#vggModel = createNetworkVGG16(img_width,img_height,img_channels)\n",
    "#resnetModel = createNetworkResnet(img_width,img_height,img_channels)\n",
    "# Load saved weights\n",
    "weights_load_path = os.path.join(experiment_rootdir, weights_path)\n",
    "\n",
    "try:\n",
    "    simpleModel.load_weights(weights_load_path)\n",
    "    print(\"Loaded model from {}\".format(weights_load_path))\n",
    "except:\n",
    "    print(\"Impossible to find weight path. Returning untrained model\")\n",
    "\n",
    "# Compile model\n",
    "#sgd = SGD(lr=initial_lr, momentum=0.9, decay=decay, nesterov=False)\n",
    "#adam = Adam(learning_rate=initial_lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "rmsprop = RMSprop(learning_rate=lrate, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
    "\n",
    "# Get predictions using predict_generator function\n",
    "STEPS_PER_EPOCH_TEST = np.ceil(nb_samples//batch_size)\n",
    "predict = simpleModel.predict_generator(test_generator, steps=STEPS_PER_EPOCH_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c9c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['category'] = np.argmax(predict, axis=-1)\n",
    "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
    "test_df['category'] = test_df['category'].replace(label_map)\n",
    "test_df['category'] = test_df['category'].replace({ 'dog': 1, 'cat': 0 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e572715",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test = test_df.head(18)\n",
    "sample_test.head()\n",
    "plt.figure(figsize=(12, 24))\n",
    "for index, row in sample_test.iterrows():\n",
    "    filename = row['filename']\n",
    "    category = row['category']\n",
    "    img = load_img(\"../DATA/dogs-vs-cats/test/\"+filename, target_size=(img_width,img_height))\n",
    "    plt.subplot(6, 3, index+1)\n",
    "    plt.imshow(img)\n",
    "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af59fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results={\n",
    "    0:'cat',\n",
    "    1:'dog'\n",
    "}\n",
    "\n",
    "im=Image.open(\"__image_path_TO_custom_image\")\n",
    "im=im.resize(Image_Size)\n",
    "im=np.expand_dims(im,axis=0)\n",
    "im=np.array(im)\n",
    "im=im/255\n",
    "pred=model.predict_classes([im])[0]\n",
    "print(pred,results[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a9988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "# Save the figure\n",
    "accuracy_path = os.path.join(experiment_rootdir, 'accuracy.png')\n",
    "plt.savefig(accuracy_path)\n",
    "\n",
    "# Show figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4322e06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "# Save the figure\n",
    "loss_path = os.path.join(experiment_rootdir, 'loss.png')\n",
    "plt.savefig(loss_path)\n",
    "\n",
    "# Show figure\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
